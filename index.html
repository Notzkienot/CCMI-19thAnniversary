<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CCMI 19th Anniversary ‚Äì Head Tracking Camera</title>
  <style>
    body {
      margin: 0;
      height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      font-family: "Poppins", system-ui, sans-serif;
      color: #fff;
      background: linear-gradient(135deg, #2b0047, #7b2cbf, #c77dff);
      background-size: 400% 400%;
      animation: bgMove 10s ease infinite;
      overflow: hidden;
    }
    @keyframes bgMove {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }
    .camera-container {
      position: relative;
      width: 90vw;
      max-width: 420px;
      aspect-ratio: 3/4;
      border: 3px solid gold;
      border-radius: 16px;
      box-shadow: 0 0 30px rgba(255, 215, 0, 0.45);
      overflow: hidden;
      background: #000;
    }
    video, img.preview {
      width: 100%;
      height: 100%;
      object-fit: cover;
      display: block;
    }
    img.preview { display: none; }
    .moving-text {
      position: absolute;
      left: 50%;
      top: 50%;
      transform: translate(-50%, -120%);
      font-weight: 800;
      font-size: clamp(18px, 6vw, 32px);
      text-align: center;
      background: linear-gradient(135deg, #2b0047, #7b2cbf, #c77dff);
      -webkit-background-clip: text;
      background-clip: text;
      color: transparent;
      animation: textGrad 4s ease infinite;
      text-shadow: 0 0 8px rgba(255,215,0,0.35);
      pointer-events: none;
    }
    @keyframes textGrad {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }
    .controls {
      margin-top: 16px;
      display: flex;
      gap: 12px;
    }
    button, a.button {
      background: linear-gradient(135deg, gold, #ffef9f);
      color: #4b0082;
      border: none;
      padding: 12px 28px;
      border-radius: 10px;
      font-size: 16px;
      font-weight: 700;
      cursor: pointer;
      text-decoration: none;
      box-shadow: 0 4px 10px rgba(0,0,0,0.35);
      transition: transform 0.15s ease, box-shadow 0.15s ease;
    }
    button:hover, a.button:hover {
      transform: scale(1.04);
      box-shadow: 0 0 14px rgba(255, 215, 0, 0.6);
    }
    #download, #retake { display: none; }
  </style>
</head>
<body>
  <div class="camera-container" id="cameraBox">
    <video id="camera" autoplay playsinline></video>
    <img id="capturedImage" class="preview" />
    <div id="movingText" class="moving-text">CCMI 19th Anniversary</div>
  </div>

  <div class="controls">
    <button id="capture">üì∏ Capture</button>
    <button id="retake">üîÑ Retake</button>
    <a id="download" class="button" href="#" download="photo.png">‚¨áÔ∏è Download</a>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script>
    const video = document.getElementById('camera');
    const movingText = document.getElementById('movingText');
    const imgPreview = document.getElementById('capturedImage');
    const captureBtn = document.getElementById('capture');
    const retakeBtn = document.getElementById('retake');
    const downloadBtn = document.getElementById('download');
    const cameraBox = document.getElementById('cameraBox');
    let stream, runTrack = false;

    async function startCamera() {
      stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
      video.srcObject = stream;
      await video.play();
    }

    async function loadModels() {
      console.log("Loading models...");
      // Match EXACT filenames in your models folder
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models/');
      await faceapi.nets.faceLandmark68TinyNet.loadFromUri('./models/');
      console.log("‚úÖ Models loaded successfully!");
    }

    function lerp(a, b, t) { return a + (b - a) * t; }

    async function trackFace() {
      const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.4 });
      let tx = cameraBox.clientWidth / 2, ty = cameraBox.clientHeight / 2;

      const loop = async () => {
        if (!runTrack) return;

        const result = await faceapi
          .detectSingleFace(video, options)
          .withFaceLandmarks(true);

        if (result?.landmarks) {
          const nose = result.landmarks.getNose();
          const cx = result.detection.box.x + result.detection.box.width / 2;
          const cy = nose[0].y - 100; // Move text ABOVE head

          tx = lerp(tx, cx, 0.25);
          ty = lerp(ty, cy, 0.25);

          const scaleX = cameraBox.clientWidth / video.videoWidth;
          const scaleY = cameraBox.clientHeight / video.videoHeight;
          movingText.style.left = `${tx * scaleX}px`;
          movingText.style.top = `${ty * scaleY}px`;
          movingText.style.transform = 'translate(-50%, -100%)';
        }

        requestAnimationFrame(loop);
      };
      requestAnimationFrame(loop);
    }

    async function init() {
      try {
        await loadModels();
        await startCamera();
        runTrack = true;
        trackFace();
      } catch (err) {
        alert('Camera or model load failed. Check HTTPS and model filenames.');
        console.error(err);
      }
    }

    // Capture Image
    captureBtn.addEventListener('click', () => {
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d');

      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const grad = ctx.createLinearGradient(0, 0, canvas.width, canvas.height);
      grad.addColorStop(0, '#2b0047');
      grad.addColorStop(0.5, '#7b2cbf');
      grad.addColorStop(1, '#c77dff');

      const boxW = cameraBox.clientWidth;
      const boxH = cameraBox.clientHeight;
      const scaleX = canvas.width / boxW;
      const scaleY = canvas.height / boxH;

      const rect = movingText.getBoundingClientRect();
      const parentRect = cameraBox.getBoundingClientRect();
      const xScreen = rect.left - parentRect.left + rect.width / 2;
      const yScreen = rect.top - parentRect.top;

      const x = xScreen * scaleX;
      const y = yScreen * scaleY;

      ctx.font = `800 ${Math.round(boxW * 0.08)}px Poppins, sans-serif`;
      ctx.textAlign = 'center';
      ctx.textBaseline = 'bottom';
      ctx.fillStyle = grad;
      ctx.shadowColor = 'rgba(255,215,0,0.6)';
      ctx.shadowBlur = 20;
      ctx.fillText('CCMI 19th Anniversary', x, y);

      const dataUrl = canvas.toDataURL('image/png');
      imgPreview.src = dataUrl;
      imgPreview.style.display = 'block';
      video.style.display = 'none';
      downloadBtn.href = dataUrl;
      downloadBtn.style.display = 'inline-block';
      retakeBtn.style.display = 'inline-block';
      captureBtn.style.display = 'none';
      runTrack = false;
    });

    // Retake
    retakeBtn.addEventListener('click', async () => {
      imgPreview.style.display = 'none';
      video.style.display = 'block';
      downloadBtn.style.display = 'none';
      retakeBtn.style.display = 'none';
      captureBtn.style.display = 'inline-block';
      if (!stream) await startCamera();
      runTrack = true;
      trackFace();
    });

    init();
  </script>
</body>
</html>
